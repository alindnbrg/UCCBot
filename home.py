import streamlit as st
import ai
import time

# Initialize the LLM object
llm = ai.AzureGPT4Chat()

def app():
    st.subheader("Use Case Classifier")

    # Add a collapsible disclaimer
    with st.expander("Disclaimer"):
        st.write("This is a simulated conversation. Responses are generated by AI and may not always be accurate or appropriate.")

    # Initialize chat history with the bot's first message
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "Hello! I'm your AI assistant specialized in classifying use cases. Tell me about your project or idea, and I'll help you map it to the right LLM use case archetypes. I can also guide you through the necessary components to bring your vision to life. Let's get started - share your idea with me!"}
        ]

    # Display chat messages from history on app rerun
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Accept user input
    if prompt := st.chat_input("Share your idea or ask a question..."):
        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": prompt})

        # Display user message in chat message container
        with st.chat_message("user"):
            st.markdown(prompt)

        # Use a placeholder for the assistant's response
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""

            # Show a loading spinner while generating the response
            with st.spinner("thinking... ðŸ¤”"):
                assistant_response = llm(prompt)  # Get the response from the LLM
                time.sleep(1)  # Optional delay to simulate processing

            # Display the generated response
            for chunk in assistant_response.split(' '):
                full_response += chunk + " "
                time.sleep(0.05)  # Simulate typing, adjust as needed
                message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)

        # Add assistant response to chat history
        st.session_state.messages.append({"role": "assistant", "content": full_response})

if __name__ == "__main__":
    app()
